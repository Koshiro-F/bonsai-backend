#!/usr/bin/env python3
"""
DocumentAI ã‚’ç”¨ã„ã¦ PDF ã‚’OCRã—ã€ãƒšãƒ¼ã‚¸ã”ã¨ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’CSVã«ä¿å­˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
OpenAI ã¯ä½¿ç”¨ã›ãšã€ãƒšãƒ¼ã‚¸å˜ä½ã§æŠ½å‡ºã—ãŸã€Œå†…å®¹ã€ã®ã¿ã‚’æ ¼ç´ã—ã¾ã™ã€‚

å‡ºåŠ›CSVã‚«ãƒ©ãƒ : filename, page, content
"""

import os
import csv
import tempfile
from typing import List, Dict, Optional, Tuple, Set

from dotenv import load_dotenv
from google.cloud import documentai
import fitz  # PyMuPDF


# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆä½ç½®ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã§è§£æ±ºï¼‰
_BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
_ENV_PATH = os.path.join(_BASE_DIR, ".env.local")
load_dotenv(dotenv_path=_ENV_PATH)


class OCRPageExporter:
    """DocumentAIã‚’ä½¿ã£ã¦PDFã‹ã‚‰ãƒšãƒ¼ã‚¸å˜ä½ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦CSVä¿å­˜ã™ã‚‹"""

    def __init__(self, imageless: bool = True):
        # DocumentAIè¨­å®š
        self.project_id = "utopian-saga-466802-m5"
        self.location = "us"
        self.processor_id = "e794632016082b0"
        self.processor_version = "pretrained-ocr-v2.0-2023-06-02"
        self.client = documentai.DocumentProcessorServiceClient()
        # ç”»åƒæŠ½å‡ºã‚’çœç•¥ã™ã‚‹imagelessãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒšãƒ¼ã‚¸ä¸Šé™ã®ç·©å’Œã‚’ç‹™ã†ï¼‰ã€‚
        self.imageless = imageless

    def _get_documentai_document(self, pdf_path: str):
        """DocumentAIã§PDFã‚’å‡¦ç†ã—ã€documentã‚’è¿”ã™"""
        name = self.client.processor_version_path(
            self.project_id, self.location, self.processor_id, self.processor_version
        )

        with open(pdf_path, "rb") as pdf_file:
            pdf_content = pdf_file.read()

        # imagelessãƒ¢ãƒ¼ãƒ‰æŒ‡å®šï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰ã€‚å¤±æ•—æ™‚ã¯é€šå¸¸ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å†è©¦è¡Œã€‚
        request = None
        if self.imageless:
            try:
                request = documentai.ProcessRequest(
                    name=name,
                    raw_document=documentai.RawDocument(content=pdf_content, mime_type="application/pdf"),
                    process_options=documentai.ProcessOptions(
                        # ç”»åƒé–¢é€£æŠ½å‡ºã‚’ç„¡åŠ¹åŒ–ï¼ˆimagelessç›¸å½“ï¼‰
                        enable_image_extraction=False,
                        # ãƒã‚¤ãƒ†ã‚£ãƒ–PDFãƒ‘ãƒ¼ã‚¹ã‚’æœ‰åŠ¹åŒ–
                        ocr_config=documentai.OcrConfig(
                            enable_native_pdf_parsing=True
                        )
                    )
                )
            except Exception:
                request = None

        if request is None:
            request = documentai.ProcessRequest(
                name=name,
                raw_document=documentai.RawDocument(content=pdf_content, mime_type="application/pdf"),
            )

        result = self.client.process_document(request=request)
        return result.document

    def _process_selected_pages_with_documentai(self, pdf_path: str, zero_based_indices: List[int]):
        """é¸æŠãƒšãƒ¼ã‚¸ã®ã¿ã‚’æŠ½å‡ºã—ã¦ä¸€æ™‚PDFã‚’ä½œæˆã—ã€DocumentAIã§å‡¦ç†

        Returns: (documentai.Document, List[int] original_page_numbers)
        """
        # å…ƒPDFã‹ã‚‰å¯¾è±¡ãƒšãƒ¼ã‚¸ã®ã¿æŠ½å‡º
        src = fitz.open(pdf_path)
        dst = fitz.open()
        for idx in zero_based_indices:
            if 0 <= idx < len(src):
                dst.insert_pdf(src, from_page=idx, to_page=idx)
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        fd, tmp_path = tempfile.mkstemp(suffix=".pdf")
        os.close(fd)
        try:
            dst.save(tmp_path)
        finally:
            dst.close()
            src.close()

        # ä¸€æ™‚PDFã‚’DocumentAIã§å‡¦ç†
        try:
            document = self._get_documentai_document(tmp_path)
        finally:
            try:
                os.remove(tmp_path)
            except OSError:
                pass

        # ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå‡ºåŠ›ã®ãƒšãƒ¼ã‚¸é †ã¯zero_based_indicesã®é †ï¼‰
        original_page_numbers = [i + 1 for i in zero_based_indices]
        return document, original_page_numbers

    def _extract_text_from_layout(self, layout, full_text: str) -> str:
        """ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã‹ã‚‰è©²å½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        if not layout or not getattr(layout, "text_anchor", None):
            return ""

        text_segments: List[str] = []
        for segment in layout.text_anchor.text_segments:
            start_index = int(segment.start_index) if segment.start_index else 0
            end_index = int(segment.end_index) if segment.end_index else len(full_text)
            text_segments.append(full_text[start_index:end_index])

        return "".join(text_segments)

    def _extract_table_text(self, table, full_text: str) -> str:
        """ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šã§æ•´å½¢"""
        table_rows: List[str] = []
        for row in table.body_rows:
            row_cells: List[str] = []
            for cell in row.cells:
                cell_text = self._extract_text_from_layout(cell.layout, full_text)
                row_cells.append(cell_text.strip())
            if any(cell for cell in row_cells):
                table_rows.append(" | ".join(row_cells))
        return "\n".join(table_rows) if table_rows else ""

    def _extract_bbox(self, layout) -> Dict[str, float]:
        """Bounding Boxã‚’æŠ½å‡º (y1, x1ã§ã‚½ãƒ¼ãƒˆç”¨)"""
        if not layout or not getattr(layout, "bounding_poly", None):
            return {"x1": 0, "y1": 0, "x2": 0, "y2": 0}
        vertices = layout.bounding_poly.vertices
        if not vertices or len(vertices) < 4:
            return {"x1": 0, "y1": 0, "x2": 0, "y2": 0}
        x_coords = [v.x for v in vertices if hasattr(v, "x")]
        y_coords = [v.y for v in vertices if hasattr(v, "y")]
        return {"x1": min(x_coords), "y1": min(y_coords), "x2": max(x_coords), "y2": max(y_coords)}

    def _extract_page_content(self, document, page_index: int) -> str:
        """æŒ‡å®šãƒšãƒ¼ã‚¸ã®å†…å®¹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦è¿”ã™ã€‚
        ã‚«ãƒ©ãƒ æ¨å®šã¯è¡Œã‚ãšã€è¦ç´ ã¯ yï¼ˆä¸Šâ†’ä¸‹ï¼‰ã§è¡Œã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€
        åŒä¸€è¡Œã§ã¯ xï¼ˆå³â†’å·¦ï¼‰ã«æ•´åˆ—ã€‚æ®µè½ã¯ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã§çµåˆã€‚
        """
        if page_index >= len(document.pages):
            return ""
        page = document.pages[page_index]

        elements: List[Dict] = []

        # æ®µè½
        if hasattr(page, "paragraphs") and page.paragraphs:
            for para in page.paragraphs:
                text = self._extract_text_from_layout(para.layout, document.text)
                if text.strip():
                    bbox = self._extract_bbox(para.layout)
                    elements.append({
                        "type": "paragraph",
                        "text": text.strip(),
                        "bbox": bbox
                    })

        # è¡¨
        if hasattr(page, "tables") and page.tables:
            for table in page.tables:
                table_text = self._extract_table_text(table, document.text)
                if table_text:
                    bbox = self._extract_bbox(table.layout) if getattr(table, "layout", None) else {}
                    elements.append({
                        "type": "table",
                        "text": table_text,
                        "bbox": bbox
                    })

        if not elements:
            return ""

        # ãƒšãƒ¼ã‚¸ã‚µã‚¤ã‚ºã®æ¨å®šï¼ˆé–¾å€¤è¨­å®šã®ãŸã‚ï¼‰
        min_x = min(el["bbox"].get("x1", 0) for el in elements)
        max_x = max(el["bbox"].get("x2", 0) for el in elements)
        min_y = min(el["bbox"].get("y1", 0) for el in elements)
        max_y = max(el["bbox"].get("y2", 0) for el in elements)
        page_width = max(1.0, max_x - min_x)
        page_height = max(1.0, max_y - min_y)
        page_diag = (page_width ** 2 + page_height ** 2) ** 0.5

        # yåº§æ¨™ã‚’é›¢æ•£åŒ–ï¼ˆè¨±å®¹èª¤å·®å†…ã®è¦ç´ ã¯åŒã˜è¡Œã¨ã—ã¦æ‰±ã†ï¼‰
        def y_center(b):
            return (b.get("y1", 0) + b.get("y2", 0)) / 2.0

        y_tolerance = page_height * 0.1  # ã»ã¼åŒã˜é«˜ã•ã¨ã¿ãªã™è¨±å®¹ç¯„å›²ï¼ˆ1%ï¼‰

        # ã¾ãšyä¸­å¿ƒã§ã‚½ãƒ¼ãƒˆ
        elements.sort(key=lambda x: (y_center(x["bbox"]), x["bbox"].get("x1", 0)))

        # ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°: è¿‘ã„yï¼ˆÂ±y_toleranceï¼‰ã‚’åŒã˜è¡Œã‚°ãƒ«ãƒ¼ãƒ—ã«ã¾ã¨ã‚ã‚‹
        row_groups: List[List[Dict]] = []
        current_group: List[Dict] = []
        current_y: Optional[float] = None

        for el in elements:
            yc = y_center(el["bbox"]) if el.get("bbox") else 0
            if current_group and current_y is not None and abs(yc - current_y) <= y_tolerance:
                current_group.append(el)
                # ä»£è¡¨yã¯åˆæœŸå€¤ã‚’ç¶­æŒï¼ˆãƒ‰ãƒªãƒ•ãƒˆé˜²æ­¢ï¼‰
            else:
                if current_group:
                    row_groups.append(current_group)
                current_group = [el]
                current_y = yc
        if current_group:
            row_groups.append(current_group)

        # å„è¡Œã‚°ãƒ«ãƒ¼ãƒ—å†…ã‚’xã§é™é †ã‚½ãƒ¼ãƒˆã—ã€è¡Œã‚°ãƒ«ãƒ¼ãƒ—é †ã«ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆä¸Šâ†’ä¸‹ã€åŒã˜è¡Œã¯å³â†’å·¦ï¼‰
        for g in row_groups:
            g.sort(key=lambda e: e["bbox"].get("x1", 0), reverse=True)
        elements = [e for g in row_groups for e in g]

        # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®é–¾å€¤ï¼ˆãƒšãƒ¼ã‚¸å¯¾è§’ã®å‰²åˆï¼‰
        distance_threshold = page_diag * 0.1  # 10% ç¨‹åº¦

        def center(b):
            return ((b.get("x1", 0) + b.get("x2", 0)) / 2.0,
                    (b.get("y1", 0) + b.get("y2", 0)) / 2.0)

        def euclid(b1, b2) -> float:
            x1, y1 = center(b1)
            x2, y2 = center(b2)
            dx, dy = (x2 - x1), (y2 - y1)
            return (dx * dx + dy * dy) ** 0.5

        merged: List[Dict] = []
        current_block: Optional[Dict] = None

        for item in elements:
            if item["type"] == "table":
                # è¡¨ã¯ç‹¬ç«‹ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦é…ç½®ã€æ®µè½çµåˆã¯ãƒªã‚»ãƒƒãƒˆ
                if current_block:
                    merged.append(current_block)
                    current_block = None
                merged.append(item)
                continue

            # paragraph
            if current_block is None:
                current_block = {"type": "paragraph", "text": item["text"], "bbox": item["bbox"]}
                continue

            dist = euclid(current_block["bbox"], item["bbox"]) if current_block else 1e9
            if dist <= distance_threshold:
                # è¿‘ã„æ®µè½ã¯çµåˆï¼ˆå˜ç´”çµåˆï¼‰
                current_block["text"] = current_block["text"].rstrip() + "\n" + item["text"].lstrip()
                # bboxã®çµ±åˆ
                cb = current_block["bbox"]
                ib = item["bbox"]
                cb["x1"] = min(cb.get("x1", 0), ib.get("x1", 0))
                cb["y1"] = min(cb.get("y1", 0), ib.get("y1", 0))
                cb["x2"] = max(cb.get("x2", 0), ib.get("x2", 0))
                cb["y2"] = max(cb.get("y2", 0), ib.get("y2", 0))
            else:
                merged.append(current_block)
                current_block = {"type": "paragraph", "text": item["text"], "bbox": item["bbox"]}

        if current_block:
            merged.append(current_block)

        # å‡ºåŠ›æ•´å½¢
        lines: List[str] = []
        for block in merged:
            if block["type"] == "table":
                lines.append("**è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿**:")
                lines.append(block["text"])  # ãã®ã¾ã¾è¤‡æ•°è¡Œ
                lines.append("")
            else:
                lines.append(block["text"])  # çµåˆæ¸ˆã¿æ®µè½
                lines.append("")

        return "\n".join(lines).strip()

    def process_file(self, pdf_path: str, selected_pages: Optional[Set[int]] = None) -> List[Dict[str, str]]:
        """1ã¤ã®PDFã‚’å‡¦ç†ã—ã€å„ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’è¿”ã™

        selected_pages: 1å§‹ã¾ã‚Šã®ãƒšãƒ¼ã‚¸ç•ªå·é›†åˆï¼ˆNoneãªã‚‰å…¨ãƒšãƒ¼ã‚¸ï¼‰
        """
        print(f"ğŸ“– OCRå‡¦ç†: {os.path.basename(pdf_path)}")
        results: List[Dict[str, str]] = []

        # ãƒšãƒ¼ã‚¸ãƒãƒƒãƒãƒ³ã‚°ï¼ˆimagelessæ™‚30/éimagelessæ™‚15ï¼‰
        def batched(lst: List[int], size: int) -> List[List[int]]:
            return [lst[i:i + size] for i in range(0, len(lst), size)]

        if selected_pages:
            zero_based_all = sorted({p - 1 for p in selected_pages if p >= 1})
        else:
            # å…¨ãƒšãƒ¼ã‚¸æŒ‡å®š: å…ƒPDFã‹ã‚‰ãƒšãƒ¼ã‚¸æ•°ã‚’å–å¾—
            with fitz.open(pdf_path) as doc:
                zero_based_all = list(range(len(doc)))

        if not zero_based_all:
            print(f"  âš ï¸ æŒ‡å®šãƒšãƒ¼ã‚¸ãŒä¸æ­£ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {os.path.basename(pdf_path)}")
            return results

        batch_limit = 30 if self.imageless else 15
        for batch in batched(zero_based_all, batch_limit):
            try:
                document, original_page_numbers = self._process_selected_pages_with_documentai(pdf_path, batch)
            except Exception as e:
                msg = str(e)
                # imagelessãŒåŠ¹ã„ã¦ã„ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: 15ãƒšãƒ¼ã‚¸ã«å†åˆ†å‰²
                if self.imageless and ("PAGE_LIMIT_EXCEEDED" in msg or "non-imageless" in msg or "page limit" in msg.lower()):
                    fallback_limit = 15
                    print(f"  âš ï¸ imagelessæœªé©ç”¨ã®å¯èƒ½æ€§ã€‚{fallback_limit}ãƒšãƒ¼ã‚¸ã«å†åˆ†å‰²ã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚")
                    for small in batched(batch, fallback_limit):
                        document, original_page_numbers = self._process_selected_pages_with_documentai(pdf_path, small)
                        print(f"  ğŸ” å†è©¦è¡Œ: {len(small)}ãƒšãƒ¼ã‚¸")
                        for tmp_idx in range(len(document.pages)):
                            orig_page_num = original_page_numbers[tmp_idx]
                            print(f"    ğŸ“„ ãƒšãƒ¼ã‚¸ {orig_page_num} ã‚’æŠ½å‡ºä¸­...")
                            content = self._extract_page_content(document, tmp_idx)
                            results.append({
                                "filename": os.path.basename(pdf_path),
                                "page": str(orig_page_num),
                                "content": content,
                            })
                    continue
                else:
                    raise

            print(f"  ğŸ”¢ ãƒšãƒ¼ã‚¸ãƒãƒƒãƒå‡¦ç†: {len(batch)}ãƒšãƒ¼ã‚¸ (ä¸Šé™ {batch_limit})")
            for tmp_idx in range(len(document.pages)):
                orig_page_num = original_page_numbers[tmp_idx]
                print(f"    ğŸ“„ ãƒšãƒ¼ã‚¸ {orig_page_num} ã‚’æŠ½å‡ºä¸­...")
                content = self._extract_page_content(document, tmp_idx)
                results.append({
                    "filename": os.path.basename(pdf_path),
                    "page": str(orig_page_num),
                    "content": content,
                })
        return results

    def process_directory(self, input_dir: str) -> List[str]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®PDFä¸€è¦§ã‚’å–å¾—"""
        pdfs: List[str] = []
        for name in sorted(os.listdir(input_dir)):
            if name.lower().endswith(".pdf"):
                pdfs.append(os.path.join(input_dir, name))
        return pdfs


def main():
    import argparse

    parser = argparse.ArgumentParser(description="DocumentAI OCR â†’ ãƒšãƒ¼ã‚¸åˆ¥CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    parser.add_argument("--output", "-o",
                        default=_BASE_DIR + "/data/ocr_pages.csv",
                        help="å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--spec", action="append", required=True,
                        help="å‡¦ç†å¯¾è±¡æŒ‡å®š: 'filename.pdf:1,3-5,10' ã®å½¢å¼ã€‚è¤‡æ•°æŒ‡å®šå¯ã€‚ç›¸å¯¾ãƒ‘ã‚¹ã¯--base-diråŸºæº–")
    parser.add_argument("--base-dir", default=_BASE_DIR + "/data/input",
                        help="--specã§ç›¸å¯¾ãƒ‘ã‚¹ã‚’è§£æ±ºã™ã‚‹åŸºæº–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--imageless", dest="imageless", action="store_true", default=True,
                        help="imagelessãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒšãƒ¼ã‚¸ä¸Šé™ã®ç·©å’Œï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹")
    parser.add_argument("--no-imageless", dest="imageless", action="store_false",
                        help="imagelessãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ï¼ˆç”»åƒæŠ½å‡ºã‚‚å«ã‚€ï¼‰")

    args = parser.parse_args()

    exporter = OCRPageExporter(imageless=args.imageless)

    def parse_pages(pages_str: str) -> Set[int]:
        pages: Set[int] = set()
        if not pages_str:
            return pages
        tokens = [t.strip() for t in pages_str.split(',') if t.strip()]
        for tok in tokens:
            if '-' in tok:
                try:
                    a, b = tok.split('-', 1)
                    start = int(a)
                    end = int(b)
                    if start <= end:
                        pages.update(range(start, end + 1))
                    else:
                        pages.update(range(end, start + 1))
                except ValueError:
                    continue
            else:
                try:
                    pages.add(int(tok))
                except ValueError:
                    continue
        return pages

    # å¯¾è±¡ã¨ãƒšãƒ¼ã‚¸æŒ‡å®šã®è§£é‡ˆ
    file_to_pages: List[Tuple[str, Optional[Set[int]]]] = []
    base_dir = args.base_dir

    if args.spec:
        # --spec å„ªå…ˆ
        for spec in args.spec:
            if ':' not in spec:
                filename = spec.strip()
                pages_set: Optional[Set[int]] = None
            else:
                filename, pages_str = spec.split(':', 1)
                filename = filename.strip()
                pages_set = parse_pages(pages_str.strip())

            # ãƒ‘ã‚¹è§£æ±º
            candidate = filename
            if not os.path.isabs(candidate):
                if os.path.isfile(candidate):
                    pass
                else:
                    candidate = os.path.join(base_dir, filename)

            if not os.path.isfile(candidate):
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename} (è§£æ±ºå…ˆ: {candidate})")
                continue

            file_to_pages.append((candidate, pages_set))
    else:
        # --specã¯requiredãªã®ã§ã“ã“ã«ã¯æ¥ãªã„ãŒå®‰å…¨ã®ãŸã‚
        print("âŒ --spec ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    if not file_to_pages:
        print("âŒ å‡¦ç†å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    print(f"ğŸ§ª å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_to_pages)}")
    all_rows: List[Dict[str, str]] = []
    for pdf_path, pages in file_to_pages:
        try:
            rows = exporter.process_file(pdf_path, selected_pages=pages)
            all_rows.extend(rows)
        except Exception as e:
            print(f"âš ï¸  å‡¦ç†å¤±æ•—: {pdf_path} ({e})")

    # CSVä¿å­˜
    if all_rows:
        os.makedirs(os.path.dirname(args.output), exist_ok=True)
        with open(args.output, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["filename", "page", "content"], quoting=csv.QUOTE_ALL)
            writer.writeheader()
            for row in all_rows:
                writer.writerow(row)
        print(f"âœ… CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {args.output} ({len(all_rows)} è¡Œ)")
    else:
        print("âš ï¸ å‡ºåŠ›ã™ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()

