#!/usr/bin/env python3
"""
DocumentAI ã‚’ç”¨ã„ã¦ PDF ã‚’OCRã—ã€ãƒšãƒ¼ã‚¸ã”ã¨ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’CSVã«ä¿å­˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
OpenAI ã¯ä½¿ç”¨ã›ãšã€ãƒšãƒ¼ã‚¸å˜ä½ã§æŠ½å‡ºã—ãŸã€Œå†…å®¹ã€ã®ã¿ã‚’æ ¼ç´ã—ã¾ã™ã€‚

å‡ºåŠ›CSVã‚«ãƒ©ãƒ : filename, page, content
"""

import os
import csv
import tempfile
from typing import List, Dict, Optional, Tuple, Set

from dotenv import load_dotenv
from google.cloud import documentai
import fitz  # PyMuPDF


# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv(dotenv_path="/Users/fujikawaakirashirou/jinshari/bonsai-backend/.env.local")


class OCRPageExporter:
    """DocumentAIã‚’ä½¿ã£ã¦PDFã‹ã‚‰ãƒšãƒ¼ã‚¸å˜ä½ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦CSVä¿å­˜ã™ã‚‹"""

    def __init__(self):
        # DocumentAIè¨­å®š
        self.project_id = "utopian-saga-466802-m5"
        self.location = "us"
        self.processor_id = "e794632016082b0"
        self.processor_version = "pretrained-ocr-v2.0-2023-06-02"
        self.client = documentai.DocumentProcessorServiceClient()

    def _get_documentai_document(self, pdf_path: str):
        """DocumentAIã§PDFã‚’å‡¦ç†ã—ã€documentã‚’è¿”ã™"""
        name = self.client.processor_version_path(
            self.project_id, self.location, self.processor_id, self.processor_version
        )

        with open(pdf_path, "rb") as pdf_file:
            pdf_content = pdf_file.read()

        request = documentai.ProcessRequest(
            name=name,
            raw_document=documentai.RawDocument(content=pdf_content, mime_type="application/pdf"),
        )

        result = self.client.process_document(request=request)
        return result.document

    def _process_selected_pages_with_documentai(self, pdf_path: str, zero_based_indices: List[int]):
        """é¸æŠãƒšãƒ¼ã‚¸ã®ã¿ã‚’æŠ½å‡ºã—ã¦ä¸€æ™‚PDFã‚’ä½œæˆã—ã€DocumentAIã§å‡¦ç†

        Returns: (documentai.Document, List[int] original_page_numbers)
        """
        # å…ƒPDFã‹ã‚‰å¯¾è±¡ãƒšãƒ¼ã‚¸ã®ã¿æŠ½å‡º
        src = fitz.open(pdf_path)
        dst = fitz.open()
        for idx in zero_based_indices:
            if 0 <= idx < len(src):
                dst.insert_pdf(src, from_page=idx, to_page=idx)
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        fd, tmp_path = tempfile.mkstemp(suffix=".pdf")
        os.close(fd)
        try:
            dst.save(tmp_path)
        finally:
            dst.close()
            src.close()

        # ä¸€æ™‚PDFã‚’DocumentAIã§å‡¦ç†
        try:
            document = self._get_documentai_document(tmp_path)
        finally:
            try:
                os.remove(tmp_path)
            except OSError:
                pass

        # ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå‡ºåŠ›ã®ãƒšãƒ¼ã‚¸é †ã¯zero_based_indicesã®é †ï¼‰
        original_page_numbers = [i + 1 for i in zero_based_indices]
        return document, original_page_numbers

    def _extract_text_from_layout(self, layout, full_text: str) -> str:
        """ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã‹ã‚‰è©²å½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        if not layout or not getattr(layout, "text_anchor", None):
            return ""

        text_segments: List[str] = []
        for segment in layout.text_anchor.text_segments:
            start_index = int(segment.start_index) if segment.start_index else 0
            end_index = int(segment.end_index) if segment.end_index else len(full_text)
            text_segments.append(full_text[start_index:end_index])

        return "".join(text_segments)

    def _extract_table_text(self, table, full_text: str) -> str:
        """ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šã§æ•´å½¢"""
        table_rows: List[str] = []
        for row in table.body_rows:
            row_cells: List[str] = []
            for cell in row.cells:
                cell_text = self._extract_text_from_layout(cell.layout, full_text)
                row_cells.append(cell_text.strip())
            if any(cell for cell in row_cells):
                table_rows.append(" | ".join(row_cells))
        return "\n".join(table_rows) if table_rows else ""

    def _extract_bbox(self, layout) -> Dict[str, float]:
        """Bounding Boxã‚’æŠ½å‡º (y1, x1ã§ã‚½ãƒ¼ãƒˆç”¨)"""
        if not layout or not getattr(layout, "bounding_poly", None):
            return {"x1": 0, "y1": 0, "x2": 0, "y2": 0}
        vertices = layout.bounding_poly.vertices
        if not vertices or len(vertices) < 4:
            return {"x1": 0, "y1": 0, "x2": 0, "y2": 0}
        x_coords = [v.x for v in vertices if hasattr(v, "x")]
        y_coords = [v.y for v in vertices if hasattr(v, "y")]
        return {"x1": min(x_coords), "y1": min(y_coords), "x2": max(x_coords), "y2": max(y_coords)}

    def _extract_page_content(self, document, page_index: int) -> str:
        """æŒ‡å®šãƒšãƒ¼ã‚¸ã®å†…å®¹ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆé †ã«ã¾ã¨ã‚ã¦è¿”ã™"""
        if page_index >= len(document.pages):
            return ""
        page = document.pages[page_index]

        elements: List[Dict] = []

        # æ®µè½
        if hasattr(page, "paragraphs") and page.paragraphs:
            for para in page.paragraphs:
                text = self._extract_text_from_layout(para.layout, document.text)
                if text.strip():
                    elements.append({
                        "type": "paragraph",
                        "text": text.strip(),
                        "bbox": self._extract_bbox(para.layout)
                    })

        # è¡¨
        if hasattr(page, "tables") and page.tables:
            for table in page.tables:
                table_text = self._extract_table_text(table, document.text)
                if table_text:
                    bbox = self._extract_bbox(table.layout) if getattr(table, "layout", None) else {}
                    elements.append({
                        "type": "table",
                        "text": table_text,
                        "bbox": bbox
                    })

        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆé †ã«ã‚½ãƒ¼ãƒˆ (y1 -> x1)
        elements.sort(key=lambda x: (x["bbox"].get("y1", 0), x["bbox"].get("x1", 0)))

        # ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢
        lines: List[str] = []
        for el in elements:
            if el["type"] == "table":
                lines.append("**è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿**:")
                lines.append(el["text"])  # ãã®ã¾ã¾è¤‡æ•°è¡Œ
                lines.append("")
            else:
                lines.append(el["text"])
                lines.append("")

        return "\n".join(lines).strip()

    def process_file(self, pdf_path: str, selected_pages: Optional[Set[int]] = None) -> List[Dict[str, str]]:
        """1ã¤ã®PDFã‚’å‡¦ç†ã—ã€å„ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’è¿”ã™

        selected_pages: 1å§‹ã¾ã‚Šã®ãƒšãƒ¼ã‚¸ç•ªå·é›†åˆï¼ˆNoneãªã‚‰å…¨ãƒšãƒ¼ã‚¸ï¼‰
        """
        print(f"ğŸ“– OCRå‡¦ç†: {os.path.basename(pdf_path)}")
        results: List[Dict[str, str]] = []

        if selected_pages:
            # 0å§‹ã¾ã‚Šã«å¤‰æ›ï¼ˆå…ƒPDFã®ç·ãƒšãƒ¼ã‚¸æ•°ã‚’çŸ¥ã‚‰ãªãã¦ã‚‚ã‚ˆã„ï¼‰
            zero_based = sorted({p - 1 for p in selected_pages if p >= 1})
            if not zero_based:
                print(f"  âš ï¸ æŒ‡å®šãƒšãƒ¼ã‚¸ãŒä¸æ­£ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {os.path.basename(pdf_path)}")
                return results
            # æŒ‡å®šãƒšãƒ¼ã‚¸ã®ã¿ã§ä¸€æ™‚PDFã‚’ä½œæˆã—ã¦DocumentAIã«æ¸¡ã™ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™å¯¾ç­–ï¼‰
            document, original_page_numbers = self._process_selected_pages_with_documentai(pdf_path, zero_based)
            total_pages_tmp = len(document.pages)
            print(f"  ğŸ”¢ æŒ‡å®šãƒšãƒ¼ã‚¸: {', '.join(str(p) for p in sorted(selected_pages))} â†’ æŠ½å‡º{total_pages_tmp}ãƒšãƒ¼ã‚¸")

            for tmp_idx in range(total_pages_tmp):
                orig_page_num = original_page_numbers[tmp_idx]
                print(f"  ğŸ“„ ãƒšãƒ¼ã‚¸ {orig_page_num} ã‚’æŠ½å‡ºä¸­...")
                content = self._extract_page_content(document, tmp_idx)
                results.append({
                    "filename": os.path.basename(pdf_path),
                    "page": str(orig_page_num),
                    "content": content,
                })
        else:
            # å…¨ãƒšãƒ¼ã‚¸å‡¦ç†ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã‚‹å ´åˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ--specã§ç¯„å›²æŒ‡å®šæ¨å¥¨ï¼‰
            document = self._get_documentai_document(pdf_path)
            total_pages = len(document.pages)
            for idx in range(total_pages):
                page_num = idx + 1
                print(f"  ğŸ“„ ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã‚’æŠ½å‡ºä¸­...")
                content = self._extract_page_content(document, idx)
                results.append({
                    "filename": os.path.basename(pdf_path),
                    "page": str(page_num),
                    "content": content,
                })
        return results

    def process_directory(self, input_dir: str) -> List[str]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®PDFä¸€è¦§ã‚’å–å¾—"""
        pdfs: List[str] = []
        for name in sorted(os.listdir(input_dir)):
            if name.lower().endswith(".pdf"):
                pdfs.append(os.path.join(input_dir, name))
        return pdfs


def main():
    import argparse

    parser = argparse.ArgumentParser(description="DocumentAI OCR â†’ ãƒšãƒ¼ã‚¸åˆ¥CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    parser.add_argument("--output", "-o",
                        default="/Users/fujikawaakirashirou/jinshari/bonsai-backend/data/ocr_pages.csv",
                        help="å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--spec", action="append", required=True,
                        help="å‡¦ç†å¯¾è±¡æŒ‡å®š: 'filename.pdf:1,3-5,10' ã®å½¢å¼ã€‚è¤‡æ•°æŒ‡å®šå¯ã€‚ç›¸å¯¾ãƒ‘ã‚¹ã¯--base-diråŸºæº–")
    parser.add_argument("--base-dir", default="/Users/fujikawaakirashirou/jinshari/bonsai-backend/data/input",
                        help="--specã§ç›¸å¯¾ãƒ‘ã‚¹ã‚’è§£æ±ºã™ã‚‹åŸºæº–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")

    args = parser.parse_args()

    exporter = OCRPageExporter()

    def parse_pages(pages_str: str) -> Set[int]:
        pages: Set[int] = set()
        if not pages_str:
            return pages
        tokens = [t.strip() for t in pages_str.split(',') if t.strip()]
        for tok in tokens:
            if '-' in tok:
                try:
                    a, b = tok.split('-', 1)
                    start = int(a)
                    end = int(b)
                    if start <= end:
                        pages.update(range(start, end + 1))
                    else:
                        pages.update(range(end, start + 1))
                except ValueError:
                    continue
            else:
                try:
                    pages.add(int(tok))
                except ValueError:
                    continue
        return pages

    # å¯¾è±¡ã¨ãƒšãƒ¼ã‚¸æŒ‡å®šã®è§£é‡ˆ
    file_to_pages: List[Tuple[str, Optional[Set[int]]]] = []
    base_dir = args.base_dir

    if args.spec:
        # --spec å„ªå…ˆ
        for spec in args.spec:
            if ':' not in spec:
                filename = spec.strip()
                pages_set: Optional[Set[int]] = None
            else:
                filename, pages_str = spec.split(':', 1)
                filename = filename.strip()
                pages_set = parse_pages(pages_str.strip())

            # ãƒ‘ã‚¹è§£æ±º
            candidate = filename
            if not os.path.isabs(candidate):
                if os.path.isfile(candidate):
                    pass
                else:
                    candidate = os.path.join(base_dir, filename)

            if not os.path.isfile(candidate):
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename} (è§£æ±ºå…ˆ: {candidate})")
                continue

            file_to_pages.append((candidate, pages_set))
    else:
        # --specã¯requiredãªã®ã§ã“ã“ã«ã¯æ¥ãªã„ãŒå®‰å…¨ã®ãŸã‚
        print("âŒ --spec ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    if not file_to_pages:
        print("âŒ å‡¦ç†å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    print(f"ğŸ§ª å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_to_pages)}")
    all_rows: List[Dict[str, str]] = []
    for pdf_path, pages in file_to_pages:
        try:
            rows = exporter.process_file(pdf_path, selected_pages=pages)
            all_rows.extend(rows)
        except Exception as e:
            print(f"âš ï¸  å‡¦ç†å¤±æ•—: {pdf_path} ({e})")

    # CSVä¿å­˜
    if all_rows:
        os.makedirs(os.path.dirname(args.output), exist_ok=True)
        with open(args.output, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["filename", "page", "content"], quoting=csv.QUOTE_ALL)
            writer.writeheader()
            for row in all_rows:
                writer.writerow(row)
        print(f"âœ… CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {args.output} ({len(all_rows)} è¡Œ)")
    else:
        print("âš ï¸ å‡ºåŠ›ã™ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()

