# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–AIãƒãƒ£ãƒƒãƒˆ
import json
from typing import List, Tuple

from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from langchain.schema.messages import HumanMessage
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

load_dotenv(dotenv_path="/home/fujikawa/jinshari/flask-bonsai/.env.local")

TOP_K = 5

VECTORSTORE_PATH = "/home/fujikawa/jinshari/flask-bonsai/data/vectorstore"


class RAGChatBot:
    def __init__(self, show_content=False):
        print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002",
        )
        self.vectorstore = Chroma(
            embedding_function=self.embeddings, persist_directory=VECTORSTORE_PATH
        )
        self.documents = self.vectorstore.get()
        self.docs = self.documents["documents"]
        self.metadatas = self.documents["metadatas"]
        
        print("BM25ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’åˆæœŸåŒ–ä¸­...")
        self.keyword_retriever = BM25Retriever.from_texts(
            self.documents["documents"],
            metadatas=self.documents["metadatas"],
            preprocess_func=self.preprocess_func,
        )
        self.vector_retriever = self.vectorstore.as_retriever(
            search_kwargs={"k": TOP_K}
        )
        self.system_message = (
            """ã‚ãªãŸã¯ç›†æ ½ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã«ä¸ãˆã‚‰ã‚ŒãŸç›†æ ½ã®å°‚é–€æ–‡æ›¸ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
            ãªã‚‹ã¹ãå°‚é–€æ–‡æ›¸ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å›ç­”ã™ã‚‹ã‚ˆã†ã«ã—ã€ä¸æ­£ç¢ºãªéƒ¨åˆ†ãŒã‚ã‚Œã°æ–­å®šã¯é¿ã‘ã¦ãã ã•ã„ã€‚
            æ¨æ¸¬ã«åŸºã¥ãå›ç­”ã‚’ã™ã‚‹å ´åˆã¯ã€ãã®æ—¨ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚"""
        )
        self.llm = ChatOpenAI(model="gpt-4.1-nano")
        
        # ä¼šè©±å±¥æ­´ã‚’ä¿æŒ
        self.chat_history = []
        self.show_content = show_content
        
        print("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    def main(self):
        print("=" * 50)
        print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ™ãƒ¼ã‚¹AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
        print("=" * 50)
        print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚çµ‚äº†ã™ã‚‹ã«ã¯ 'quit', 'exit', 'q' ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        print("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã«ã¯ 'clear' ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        print("-" * 50)
        print("å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚‚è¡¨ç¤ºã™ã‚‹: {}".format("ON" if self.show_content else "OFF"))
        
        while True:
            try:
                user_input = input("\nã‚ãªãŸ: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                elif user_input.lower() == 'clear':
                    self.chat_history = []
                    print("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
                    continue
                elif not user_input:
                    print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    continue
                
                print("\næ¤œç´¢ä¸­...")
                response, metadata_list, referenced_docs = self.run_chat(user_input)
                print(f"\nAI: {response}")
                
                # å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¡¨ç¤º
                self.display_referenced_documents(metadata_list, referenced_docs, show_content=self.show_content)
                
                # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                self.chat_history.append({"role": "user", "content": user_input})
                self.chat_history.append({"role": "assistant", "content": response})
                
                # ä¼šè©±å±¥æ­´ãŒé•·ããªã‚Šã™ããŸå ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                if len(self.chat_history) > 10:
                    self.chat_history = self.chat_history[-10:]
                    
            except KeyboardInterrupt:
                print("\n\nãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            except Exception as e:
                print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue

    def run_chat(self, question: str) -> Tuple[str, list]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦RAGã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹
        
        Args:
            question (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            
        Returns:
            Tuple[str, list]: ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã¨å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        result, metadata_list, referenced_docs = self.generate_output(
            self.keyword_retriever, 
            self.vector_retriever, 
            question, 
            self.system_message
        )
        return result, metadata_list, referenced_docs

    def preprocess_func(self, text: str) -> List[str]:
        i, j = 3, 5
        if len(text) < i:
            return [text]
        return self.generate_character_ngrams(text, i, j, True)

    def generate_character_ngrams(self, text, i, j, binary=False):
        """
        æ–‡å­—åˆ—ã‹ã‚‰æŒ‡å®šã—ãŸæ–‡å­—æ•°ã®n-gramã‚’ç”Ÿæˆ
        
        :param text: æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿
        :param i: n-gramã®æœ€å°æ–‡å­—æ•°
        :param j: n-gramã®æœ€å¤§æ–‡å­—æ•°
        :param binary: Trueã®å ´åˆã€é‡è¤‡ã‚’å‰Šé™¤
        :return: n-gramã®ãƒªã‚¹ãƒˆ
        """
        ngrams = []

        for n in range(i, j + 1):
            for k in range(len(text) - n + 1):
                ngram = text[k : k + n]
                ngrams.append(ngram)

        if binary:
            ngrams = list(set(ngrams))  # é‡è¤‡ã‚’å‰Šé™¤

        return ngrams

    def generate_output(
        self, keyword_retriever, vector_retriever, user_input, system_message
    ):
        question = self.regenerate_question(user_input)
        keyword_searched = keyword_retriever.invoke(question)
        vector_searched = vector_retriever.invoke(question)
        texts_retrieved = []
        metadata_list = []
        referenced_docs = []  # å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿æŒ
        for doc in vector_searched + keyword_searched:
            texts_retrieved.append(doc.page_content)
            metadata_list.append(doc.metadata)
            referenced_docs.append(doc)  # Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿æŒ
        result = self.chat_based_on_texts(texts_retrieved, question, system_message)
        return result, metadata_list, referenced_docs  # referenced_docsã‚‚è¿”ã™

    def regenerate_question(self, user_input):
        """
        ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã¦è³ªå•ã‚’å†ç”Ÿæˆã™ã‚‹
        """
        if not self.chat_history:
            return user_input
            
        prompt = ChatPromptTemplate.from_template(
            """
            æ¬¡ã®ä¼šè©±å±¥æ­´ã¨ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã‚’å…ƒã«ã€ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã‚’ç‹¬ç«‹ã—ãŸè³ªå•ã¨ã—ã¦è¨€ã„æ›ãˆã¦ãã ã•ã„ã€‚
            ----------
            ä¼šè©±ã®å±¥æ­´: {chat_history}
            ----------
            ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•: {follow_up_question}
            ----------
            ç‹¬ç«‹ã—ãŸè³ªå•:
            """
        )
        chain = prompt | self.llm
        follow_up_question = user_input
        args = {"chat_history": self.chat_history, "follow_up_question": follow_up_question}
        ans = chain.invoke(args)
        return str(ans.content)

    def chat_based_on_texts(self, texts_retrieved, question, system_message):
        texts = "\n\n".join(texts_retrieved)
        
        # ä¼šè©±å±¥æ­´ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
        history_str = ""
        for msg in self.chat_history[-4:]:  # æœ€æ–°ã®4ã¤ã®ç™ºè¨€ã®ã¿ä½¿ç”¨
            history_str += f"{msg['role']}: {msg['content']}\n"
        
        prompt_text = f"""
            {system_message}
            ----------
            ä¼šè©±è¨˜éŒ²ã‚’å…ƒã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±ã®ã‚­ãƒ£ãƒƒãƒãƒœãƒ¼ãƒ«ã‚’æˆç«‹ã•ã›ã¦ãã ã•ã„ã€‚
            ----------
            ä¼šè©±è¨˜éŒ²: {history_str}
            ----------
            å°‚é–€æ–‡æ›¸: {texts}
            ----------
            è³ªå•: {question}
            """

        return self.llm.invoke(
            [HumanMessage(content=[{"type": "text", "text": prompt_text}])]
        ).content

    def display_referenced_documents(self, metadata_list, referenced_docs, show_content=False):
        """
        å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æƒ…å ±ã‚’æ•´ç†ã—ã¦è¡¨ç¤ºã™ã‚‹
        Args:
            metadata_list (list): ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
            referenced_docs (list): å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
            show_content (bool): ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚‚è¡¨ç¤ºã™ã‚‹ã‹
        """
        if not metadata_list:
            return
        doc_info = {}
        # metadataã¨docsã‚’å¯¾å¿œä»˜ã‘ã¦å‡¦ç†
        for i, (metadata, doc) in enumerate(zip(metadata_list, referenced_docs)):
            filename = metadata.get('filename', 'ä¸æ˜ãªãƒ•ã‚¡ã‚¤ãƒ«')
            page_number = metadata.get('page_number', 'ä¸æ˜ãªãƒšãƒ¼ã‚¸')
            doc_type = metadata.get('type', 'Text')
            key = f"{filename}_page_{page_number}"
            if key not in doc_info:
                doc_info[key] = {
                    'filename': filename,
                    'page_number': page_number,
                    'types': set(),
                    'contents': set()  # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚setã‚’ä½¿ç”¨
                }
            doc_info[key]['types'].add(doc_type)
            # RAGã§å‚ç…§ã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if show_content:
                doc_info[key]['contents'].add(doc.page_content)

        if doc_info:
            print("\n" + "=" * 50)
            print("ğŸ“š å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
            print("=" * 50)
            sorted_docs = sorted(doc_info.values(), key=lambda x: (x['filename'], x['page_number']))
            for doc in sorted_docs:
                types_str = ", ".join(sorted(doc['types']))
                print(f"\nğŸ“„ {doc['filename']} (ãƒšãƒ¼ã‚¸ {doc['page_number']}) - {types_str}")
                if show_content and doc['contents']:
                    for idx, content in enumerate(sorted(doc['contents'])):  # é †åºã‚’ä¸€å®šã«
                        print(f"  [å†…å®¹{idx+1}]:")
                        print(f"  {content[:500]}{'...' if len(content)>500 else ''}")
                        print("-" * 40)
            print("=" * 50)


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--show-content', action='store_true', help='å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚‚è¡¨ç¤ºã™ã‚‹')
    args = parser.parse_args()
    try:
        chatbot = RAGChatBot(show_content=args.show_content)
        chatbot.main()
    except Exception as e:
        print(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
